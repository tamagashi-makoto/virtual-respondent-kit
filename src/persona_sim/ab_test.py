"""A/Bãƒ†ã‚¹ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‚

2ã¤ã®æ¡ˆï¼ˆãƒ—ãƒ©ãƒ³A vs ãƒ—ãƒ©ãƒ³Bï¼‰ã«å¯¾ã™ã‚‹å—å®¹æ€§ã‚’æ¯”è¼ƒæ¤œè¨¼ã™ã‚‹ã€‚
LangGraphã‚’ä½¿ç”¨ã—ã¦æ®µéšçš„ãªæ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹ã€‚
"""
import asyncio
import json
import os
from pathlib import Path
from typing import Optional

import pandas as pd
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langgraph.graph import END, START, StateGraph
from tqdm.asyncio import tqdm
from typing_extensions import TypedDict

from .config import load_config
from .llm import create_llm
from .prompts import get_persona_system_prompt


class ABTestState(TypedDict):
    """A/Bãƒ†ã‚¹ãƒˆã®çŠ¶æ…‹ã€‚"""

    persona_profile: dict
    eval_a: Optional[str]  # Aã®è©•ä¾¡ã‚³ãƒ¡ãƒ³ãƒˆ
    score_a: Optional[int]  # Aã®ã‚¹ã‚³ã‚¢
    eval_b: Optional[str]  # Bã®è©•ä¾¡ã‚³ãƒ¡ãƒ³ãƒˆ
    score_b: Optional[int]  # Bã®ã‚¹ã‚³ã‚¢
    winner: Optional[str]  # "A" or "B"
    final_reason: Optional[str]  # æ±ºå®šç†ç”±


class ABTestRunner:
    """A/Bãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¯ãƒ©ã‚¹ã€‚

    LangGraphã‚’ä½¿ç”¨ã—ã¦ã€ãƒšãƒ«ã‚½ãƒŠã«2ã¤ã®ãƒ—ãƒ©ãƒ³ã‚’è©•ä¾¡ã•ã›ã€æœ€çµ‚çš„ã«ã©ã¡ã‚‰ã‚’é¸æŠã™ã‚‹ã‹ã‚’æ±ºå®šã•ã›ã‚‹ã€‚
    """

    def __init__(self, config: Optional[dict] = None):
        """åˆæœŸåŒ–ã€‚

        Args:
            config: è¨­å®šè¾æ›¸ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ã€‚æŒ‡å®šã—ãªã„å ´åˆã¯config.yamlã‹ã‚‰èª­ã¿è¾¼ã‚€ã€‚
        """
        self.config = config or load_config()

        # LLMåˆæœŸåŒ–
        self.llm = create_llm(self.config)

        # è¨­å®šå€¤
        self.input_file = self.config["ab_test"]["input_file"]
        self.output_file = self.config["ab_test"]["output_file"]
        self.plan_a = self.config["ab_test"]["plan_a"]
        self.plan_b = self.config["ab_test"]["plan_b"]
        self.concurrent_limit = self.config.get("concurrent_limit", 10)

        # LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ§‹ç¯‰
        self.app = self._build_workflow()

    def _build_workflow(self) -> "CompiledStateGraph":
        """LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚

        Returns:
            CompiledStateGraph: ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã•ã‚ŒãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
        """
        workflow = StateGraph(ABTestState)

        workflow.add_node("evaluate_a", self._evaluate_a_node)
        workflow.add_node("evaluate_b", self._evaluate_b_node)
        workflow.add_node("decision", self._decision_node)

        # ãƒ•ãƒ­ãƒ¼: è©•ä¾¡A â†’ è©•ä¾¡B â†’ æ±ºå®šï¼ˆé †æ¬¡å®Ÿè¡Œï¼‰
        workflow.add_edge(START, "evaluate_a")
        workflow.add_edge("evaluate_a", "evaluate_b")
        workflow.add_edge("evaluate_b", "decision")
        workflow.add_edge(decision, END)

        return workflow.compile()

    async def _evaluate_a_node(self, state: ABTestState) -> dict:
        """ãƒ—ãƒ©ãƒ³Aã‚’è©•ä¾¡ã™ã‚‹ãƒãƒ¼ãƒ‰ã€‚

        Args:
            state: ç¾åœ¨ã®çŠ¶æ…‹

        Returns:
            dict: æ›´æ–°ã•ã‚ŒãŸçŠ¶æ…‹ï¼ˆeval_a, score_aï¼‰
        """
        prompt = get_persona_system_prompt(state["persona_profile"], detailed=False)
        user_msg = f"""Please look at the following ad copy, rate it out of 10, and state your reason in one sentence.

{self.plan_a}

Answer Format:
Score: (Number only)
Impression: (Impression)
"""

        response = await self.llm.ainvoke([SystemMessage(content=prompt), HumanMessage(content=user_msg)])
        content = response.content

        try:
            score_line = [line for line in content.split("\n") if "Score" in line or "ç‚¹æ•°" in line]
            if score_line:
                score = int(score_line[0].split(":")[-1].strip())
            else:
                score = 5
        except Exception:
            score = 5

        return {"eval_a": content, "score_a": score}

    async def _evaluate_b_node(self, state: ABTestState) -> dict:
        """ãƒ—ãƒ©ãƒ³Bã‚’è©•ä¾¡ã™ã‚‹ãƒãƒ¼ãƒ‰ã€‚

        Args:
            state: ç¾åœ¨ã®çŠ¶æ…‹

        Returns:
            dict: æ›´æ–°ã•ã‚ŒãŸçŠ¶æ…‹ï¼ˆeval_b, score_bï¼‰
        """
        prompt = get_persona_system_prompt(state["persona_profile"], detailed=False)
        user_msg = f"""Please look at the following ad copy, rate it out of 10, and state your reason in one sentence.

{self.plan_b}

Answer Format:
Score: (Number only)
Impression: (Impression)
"""

        response = await self.llm.ainvoke([SystemMessage(content=prompt), HumanMessage(content=user_msg)])
        content = response.content

        try:
            score_line = [line for line in content.split("\n") if "Score" in line or "ç‚¹æ•°" in line]
            if score_line:
                score = int(score_line[0].split(":")[-1].strip())
            else:
                score = 5
        except Exception:
            score = 5

        return {"eval_b": content, "score_b": score}

    async def _decision_node(self, state: ABTestState) -> dict:
        """æœ€çµ‚æ±ºå®šã‚’è¡Œã†ãƒãƒ¼ãƒ‰ã€‚

        Args:
            state: ç¾åœ¨ã®çŠ¶æ…‹

        Returns:
            dict: æ›´æ–°ã•ã‚ŒãŸçŠ¶æ…‹ï¼ˆwinner, final_reasonï¼‰
        """
        prompt = get_persona_system_prompt(state["persona_profile"], detailed=False)

        user_msg = f"""You have evaluated two plans.

ã€Your Evaluation of Plan Aã€‘
{state["eval_a"]}

ã€Your Evaluation of Plan Bã€‘
{state["eval_b"]}

Ultimately, which one do you find more attractive and want to purchase for your lifestyle and occupation?
Please answer clearly with "A" or "B" and state the decisive reason.

Answer Format:
Winner: (A or B)
Reason: (Reason text)
"""

        response = await self.llm.ainvoke([SystemMessage(content=prompt), HumanMessage(content=user_msg)])
        content = response.content

        winner = "A" if "Winner: A" in content or "å‹è€…: A" in content else "B"
        return {"winner": winner, "final_reason": content}

    async def _run_single_test(self, persona: dict, semaphore: asyncio.Semaphore) -> Optional[dict]:
        """å˜ä¸€ãƒšãƒ«ã‚½ãƒŠã«å¯¾ã—ã¦A/Bãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã™ã‚‹ã€‚

        Args:
            persona: ãƒšãƒ«ã‚½ãƒŠãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«
            semaphore: ä¸¦åˆ—å®Ÿè¡Œåˆ¶å¾¡ç”¨ã‚»ãƒãƒ•ã‚©

        Returns:
            Optional[dict]: ãƒ†ã‚¹ãƒˆçµæœ
        """
        async with semaphore:
            try:
                initial_state = {"persona_profile": persona}
                final_state = await self.app.ainvoke(initial_state)

                return {
                    "ID": persona.get("uuid"),
                    "Age": persona.get("age"),
                    "Occupation": persona.get("occupation"),
                    "Hobbies": str(persona.get("hobbies_and_interests"))[:30] + "...",
                    "Score_A": final_state.get("score_a"),
                    "Score_B": final_state.get("score_b"),
                    "Winner": final_state.get("winner"),
                    "Reason": str(final_state.get("final_reason")).replace("\n", " ")[:100] + "...",
                }
            except Exception as e:
                print(f"Error {persona.get("uuid")}: {e}")
                return None

    async def run_async(
        self,
        input_file: Optional[str] = None,
        output_file: Optional[str] = None,
        concurrent_limit: Optional[int] = None,
    ) -> pd.DataFrame:
        """å…¨ãƒšãƒ«ã‚½ãƒŠã«å¯¾ã—ã¦A/Bãƒ†ã‚¹ãƒˆã‚’éåŒæœŸã§å®Ÿè¡Œã™ã‚‹ã€‚

        Args:
            input_file: å…¥åŠ›JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            output_file: å‡ºåŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            concurrent_limit: ä¸¦åˆ—å®Ÿè¡Œæ•°ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

        Returns:
            pd.DataFrame: ãƒ†ã‚¹ãƒˆçµæœ
        """
        # ãƒ‘ã‚¹è¨­å®š
        input_file = input_file or self.input_file
        output_file = output_file or self.output_file
        concurrent_limit = concurrent_limit or self.concurrent_limit

        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(os.path.dirname(output_file), exist_ok=True)

        # ãƒšãƒ«ã‚½ãƒŠãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        from .data import load_personas

        personas = load_personas(input_file)

        print(f"âš–ï¸  AB Test Start: {len(personas)} people (Plan A vs Plan B)")

        semaphore = asyncio.Semaphore(concurrent_limit)
        tasks = [self._run_single_test(p, semaphore) for p in personas]

        results = []
        for f in tqdm(asyncio.as_completed(tasks), total=len(tasks)):
            res = await f
            if res:
                results.append(res)

        # çµæœã®ä¿å­˜
        df = pd.DataFrame(results)
        df.to_csv(output_file, index=False, encoding="utf-8-sig")

        print(f"\nâœ… Test Completed. Saved to '{output_file}'.")

        # é›†è¨ˆçµæœè¡¨ç¤º
        if not df.empty and "Winner" in df.columns:
            win_a = len(df[df["Winner"] == "A"])
            win_b = len(df[df["Winner"] == "B"])
            print("\n=== Aggregation Result ===")
            print(f"ğŸ† Plan A Wins: {win_a}")
            print(f"ğŸ† Plan B Wins: {win_b}")

            # è·æ¥­åˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆã‚¹ãƒ‹ãƒšãƒƒãƒˆï¼‰
            if "Occupation" in df.columns:
                print("\n=== Trend by Occupation (Top 5) ===")
                print(df.groupby("Winner")["Occupation"].value_counts().head(5))

        return df

    def run(
        self,
        input_file: Optional[str] = None,
        output_file: Optional[str] = None,
        concurrent_limit: Optional[int] = None,
    ) -> pd.DataFrame:
        """å…¨ãƒšãƒ«ã‚½ãƒŠã«å¯¾ã—ã¦A/Bãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã™ã‚‹ã€‚

        Args:
            input_file: å…¥åŠ›JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            output_file: å‡ºåŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            concurrent_limit: ä¸¦åˆ—å®Ÿè¡Œæ•°ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

        Returns:
            pd.DataFrame: ãƒ†ã‚¹ãƒˆçµæœ
        """
        return asyncio.run(self.run_async(input_file, output_file, concurrent_limit))
